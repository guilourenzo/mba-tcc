{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit (conda)",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='log/model_training.log', filemode='w', format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S', level=logging.INFO)\n",
    "logging.info('PROCESSO INICIADO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from keras.applications import InceptionV3\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "logging.info('BIBLIOTECAS IMPORTADAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurações do modelo\n",
    "import constants\n",
    "import callbacks\n",
    "import generators\n",
    "\n",
    "logging.info('CONFIGURAÇÕES IMPORTADAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()\n",
    "logging.info('SESSÃO REINICIALIZADA COM SUCESSO')\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "logging.info('AJUSTES DE USO DE GPU FINALIZADO COM SUCESSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PESOS DO MODELO IMPORTADOS COM SUCESSO:  2020-11-05 01:53:56.674569\n./checkpoints/weights.best_model299.hdf5\n"
     ]
    }
   ],
   "source": [
    "print('PESOS DO MODELO IMPORTADOS COM SUCESSO: ', datetime.now())\n",
    "\n",
    "height = constants.SIZES['basic']\n",
    "width = height\n",
    "weights_file = os.path.join('./checkpoints/', \"weights.best_model\" + str(height) + \".hdf5\")\n",
    "print(weights_file)\n",
    "\n",
    "logging.info('PESOS DO MODELO IMPORTADOS COM SUCESSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MODELO IMPORTADO COM SUCESSO:  2020-11-05 01:53:56.694544\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 17, 17, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 1, 1, 2048)   0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          524544      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            645         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,360,869\n",
      "Trainable params: 17,076,261\n",
      "Non-trainable params: 5,284,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('MODELO IMPORTADO COM SUCESSO: ', datetime.now())\n",
    "conv_base = load_model('./modelos/originais/nsfw.299x299.h5')\n",
    "logging.info('MODELO IMPORTADO COM SUCESSO')\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 17, 17, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 1, 1, 2048)   0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          524544      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            645         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,360,869\n",
      "Trainable params: 0\n",
      "Non-trainable params: 22,360,869\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.trainable = False\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'conv2d_56':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "logging.info('ALTERAÇÃO NAS CAMADAS DO MODELO COM SUCESSO')\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LAYERS ATUALIZADAS\n"
     ]
    }
   ],
   "source": [
    "def checkNum(s):\n",
    "    return any(map(str.isdigit, s))\n",
    "\n",
    "def ajustaLayer(model):\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if checkNum(str(layer.name)[-2:-1]):\n",
    "            layer._name = str(layer.name)[:-3] + '_' + str(i)\n",
    "        else:\n",
    "            layer._name = str(layer.name)[:-2] + '_' + str(i)\n",
    "        \n",
    "        # print(layer._name)\n",
    "    print(\"LAYERS ATUALIZADAS\")\n",
    "\n",
    "ajustaLayer(conv_base)\n",
    "logging.info('CAMADAS INICIAIS ATUALIZADAS COM SUCESSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CONFIGURAÇÃO DE NOVAS CAMADAS:  2020-11-05 01:54:03.258198\n"
     ]
    }
   ],
   "source": [
    "print('CONFIGURAÇÃO DE NOVAS CAMADAS: ', datetime.now())\n",
    "x = conv_base.layers[-2].output\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(256, activation='relu', kernel_initializer=initializers.he_normal(seed=None), kernel_regularizer=regularizers.l2(.0005))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(128, activation='relu', kernel_initializer=initializers.he_normal(seed=None), kernel_regularizer=regularizers.l2(.0005))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "# Essential to have another layer for better accuracy\n",
    "x = Dense(64,activation='relu', kernel_initializer=initializers.he_normal(seed=None))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "predictions = Dense(constants.NUM_CLASSES,  kernel_initializer=\"glorot_uniform\", activation='softmax')(x)\n",
    "\n",
    "logging.info('NOVAS CAMADAS CONFIGURADAS COM SUCESSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NOVAS CAMADAS ADICIONADAS:  2020-11-05 01:54:03.393775\n"
     ]
    }
   ],
   "source": [
    "print('NOVAS CAMADAS ADICIONADAS: ', datetime.now())\n",
    "model = Model(inputs = conv_base.input, outputs=predictions)\n",
    "\n",
    "logging.info('NOVAS CAMADAS ADICIONADAS AO MODELO COM SUCESSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(weights_file):\n",
    "        print (\"carregando: \", weights_file)\n",
    "        model.load_weights(weights_file)\n",
    "\n",
    "logging.info('VERIFICAÇÃO DE CHECKPOINT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all model callbacks\n",
    "callbacks_list = callbacks.make_callbacks(weights_file)\n",
    "\n",
    "logging.info('INICIALIZACAO DO CALLBACK REALIZADO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MODELO COMPILADO:  2020-11-05 01:54:03.516000\n"
     ]
    }
   ],
   "source": [
    "print('MODELO COMPILADO: ', datetime.now())\n",
    "# originally adam, but research says SGD with scheduler\n",
    "# opt = Adam(lr=0.001, amsgrad=True)\n",
    "opt = SGD(momentum=.9)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "logging.info('MODELO COMPILADO COM SUCESSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LEITURA DAS IMAGENS DO PROCESSO:  2020-11-05 01:54:03.556386\n",
      "Found 55000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n",
      "Found 8500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "print('LEITURA DAS IMAGENS DO PROCESSO: ', datetime.now())\n",
    "train_generator, test_generator, validation_generator = generators.create_generators(height, width)\n",
    "\n",
    "logging.info('IMAGENS IMPORTADAS COM SUCESSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start training!  2020-11-05 01:54:06.559150\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 3.2e-06.\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 1.8299 - accuracy: 0.5091 - val_loss: 1.3340 - val_accuracy: 0.5825\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3.2e-06.\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 1.7769 - accuracy: 0.5078 - val_loss: 1.2849 - val_accuracy: 0.6006\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 3.2e-06.\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 64s 643ms/step - loss: 1.7516 - accuracy: 0.5025 - val_loss: 1.2721 - val_accuracy: 0.5713\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 3.2e-06.\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 65s 652ms/step - loss: 1.6689 - accuracy: 0.5069 - val_loss: 1.2430 - val_accuracy: 0.5825\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 3.2e-06.\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.6618 - accuracy: 0.4975 - val_loss: 1.2055 - val_accuracy: 0.5931\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 67s 666ms/step - loss: 0.7323 - accuracy: 0.8550 - val_loss: 0.6233 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 69s 688ms/step - loss: 0.5897 - accuracy: 0.9344 - val_loss: 0.6545 - val_accuracy: 0.8856\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 67s 671ms/step - loss: 0.5578 - accuracy: 0.9378 - val_loss: 0.5245 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.002.\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 68s 682ms/step - loss: 0.5570 - accuracy: 0.9344 - val_loss: 0.5368 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.002.\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 67s 669ms/step - loss: 0.5170 - accuracy: 0.9506 - val_loss: 0.5171 - val_accuracy: 0.9337\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.002.\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 67s 674ms/step - loss: 0.5515 - accuracy: 0.9372 - val_loss: 0.5252 - val_accuracy: 0.9325\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.002.\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 67s 672ms/step - loss: 0.5422 - accuracy: 0.9428 - val_loss: 0.5358 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.002.\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 67s 674ms/step - loss: 0.5276 - accuracy: 0.9428 - val_loss: 0.5043 - val_accuracy: 0.9438\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.002.\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 67s 672ms/step - loss: 0.5163 - accuracy: 0.9497 - val_loss: 0.5225 - val_accuracy: 0.9356\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.002.\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 67s 673ms/step - loss: 0.5270 - accuracy: 0.9450 - val_loss: 0.5292 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 0.5118 - accuracy: 0.9514 - val_loss: 0.5242 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 67s 672ms/step - loss: 0.5128 - accuracy: 0.9419 - val_loss: 0.5264 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 67s 673ms/step - loss: 0.5246 - accuracy: 0.9434 - val_loss: 0.5062 - val_accuracy: 0.9356\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 67s 674ms/step - loss: 0.5341 - accuracy: 0.9391 - val_loss: 0.5362 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 68s 682ms/step - loss: 0.5040 - accuracy: 0.9469 - val_loss: 0.4978 - val_accuracy: 0.9481\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 67s 673ms/step - loss: 0.4980 - accuracy: 0.9461 - val_loss: 0.4806 - val_accuracy: 0.9513\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 68s 678ms/step - loss: 0.5111 - accuracy: 0.9441 - val_loss: 0.4969 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 68s 682ms/step - loss: 0.5023 - accuracy: 0.9544 - val_loss: 0.4891 - val_accuracy: 0.9475\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 68s 677ms/step - loss: 0.5002 - accuracy: 0.9513 - val_loss: 0.5352 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 67s 673ms/step - loss: 0.5082 - accuracy: 0.9456 - val_loss: 0.4951 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 67s 674ms/step - loss: 0.5155 - accuracy: 0.9453 - val_loss: 0.5060 - val_accuracy: 0.9356\n"
     ]
    }
   ],
   "source": [
    "print('Start training! ', datetime.now())\n",
    "logging.info('INICIO DO TREINAMENTO')\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    epochs=constants.TOTAL_EPOCHS,\n",
    "    steps_per_epoch=constants.STEPS_PER_EPOCH,\n",
    "    shuffle=True,\n",
    "    workers=4,\n",
    "    use_multiprocessing=False,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=constants.VALIDATION_STEPS\n",
    ")\n",
    "logging.info('FINAL DO TREINAMENTO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Modelo criado:  2020-11-05 04:26:20.813600\n"
     ]
    }
   ],
   "source": [
    "# Save it for later\n",
    "print('Modelo criado: ', datetime.now())\n",
    "\n",
    "# nude_classifier = os.path.join('./modelos/gerados/', \"nude.\" + str(width) + \"x\" + str(height) + \".h5\")\n",
    "# model.save(nude_classifier, overwrite=True)\n",
    "# logging.info('MODELO .H5 SALVO COM SUCESSO')\n",
    "\n",
    "tf.saved_model.save(model, './modelos/gerados/nude_classifier_saved/')\n",
    "logging.info('MODELO SavedModel SALVO COM SUCESSO')\n",
    "\n",
    "# model.save_weights(\"./modelos/gerados/nude_classifier_weights.\" + str(width) + \"x\" + str(height) + \"_v2.h5\", overwrite=True)\n",
    "# logging.info('PESOS DO MODELO SALVOS COM SUCESSO')\n",
    "\n",
    "# json_config = model.to_json()\n",
    "\n",
    "# json_name = os.path.join('./modelos/gerados/', \"nude_classifier.\" + str(width) + \"x\" + str(height) + \"_v2.json\")\n",
    "# with open(json_name, \"w\") as json_file:\n",
    "#     json_file.write(json_config)\n",
    "\n",
    "# logging.info('MODELO .JSON SALVO COM SUCESSO')\n",
    "\n",
    "logging.info('MODELOs SALVOS COM SUCESSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Avaliação do Modelo  2020-11-05 02:38:44.726604\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.4934 - accuracy: 0.9413\n"
     ]
    }
   ],
   "source": [
    "print('Avaliação do Modelo ', datetime.now())\n",
    "final_loss, final_accuracy = model.evaluate(test_generator, steps = constants.VALIDATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Final loss: 0.49\nFinal accuracy: 94.13%\n"
     ]
    }
   ],
   "source": [
    "print(\"Final loss: {:.2f}\".format(final_loss))\n",
    "logging.info(\"Final loss: {:.2f}\".format(final_loss))\n",
    "\n",
    "print(\"Final accuracy: {:.2f}%\".format(final_accuracy * 100))\n",
    "logging.info(\"Final accuracy: {:.2f}%\".format(final_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"279.1425pt\" version=\"1.1\" viewBox=\"0 0 385.78125 279.1425\" width=\"385.78125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 279.1425 \r\nL 385.78125 279.1425 \r\nL 385.78125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 43.78125 241.58625 \r\nL 378.58125 241.58625 \r\nL 378.58125 24.14625 \r\nL 43.78125 24.14625 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mb6ae0977cd\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.999432\" xlink:href=\"#mb6ae0977cd\" y=\"241.58625\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(55.818182 256.184687)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"119.872159\" xlink:href=\"#mb6ae0977cd\" y=\"241.58625\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(116.690909 256.184687)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"180.744886\" xlink:href=\"#mb6ae0977cd\" y=\"241.58625\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(174.382386 256.184687)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.617614\" xlink:href=\"#mb6ae0977cd\" y=\"241.58625\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(235.255114 256.184687)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.490341\" xlink:href=\"#mb6ae0977cd\" y=\"241.58625\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(296.127841 256.184687)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"363.363068\" xlink:href=\"#mb6ae0977cd\" y=\"241.58625\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(357.000568 256.184687)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_7\">\r\n     <!-- ÉPOCA -->\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\nM 35.40625 92.734375 \r\nL 44.4375 92.734375 \r\nL 33.296875 79.84375 \r\nL 25.828125 79.84375 \r\nz\r\n\" id=\"DejaVuSans-201\"/>\r\n      <path d=\"M 19.671875 64.796875 \r\nL 19.671875 37.40625 \r\nL 32.078125 37.40625 \r\nQ 38.96875 37.40625 42.71875 40.96875 \r\nQ 46.484375 44.53125 46.484375 51.125 \r\nQ 46.484375 57.671875 42.71875 61.234375 \r\nQ 38.96875 64.796875 32.078125 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.34375 72.90625 50.609375 67.359375 \r\nQ 56.890625 61.8125 56.890625 51.125 \r\nQ 56.890625 40.328125 50.609375 34.8125 \r\nQ 44.34375 29.296875 32.078125 29.296875 \r\nL 19.671875 29.296875 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-80\"/>\r\n      <path d=\"M 39.40625 66.21875 \r\nQ 28.65625 66.21875 22.328125 58.203125 \r\nQ 16.015625 50.203125 16.015625 36.375 \r\nQ 16.015625 22.609375 22.328125 14.59375 \r\nQ 28.65625 6.59375 39.40625 6.59375 \r\nQ 50.140625 6.59375 56.421875 14.59375 \r\nQ 62.703125 22.609375 62.703125 36.375 \r\nQ 62.703125 50.203125 56.421875 58.203125 \r\nQ 50.140625 66.21875 39.40625 66.21875 \r\nz\r\nM 39.40625 74.21875 \r\nQ 54.734375 74.21875 63.90625 63.9375 \r\nQ 73.09375 53.65625 73.09375 36.375 \r\nQ 73.09375 19.140625 63.90625 8.859375 \r\nQ 54.734375 -1.421875 39.40625 -1.421875 \r\nQ 24.03125 -1.421875 14.8125 8.828125 \r\nQ 5.609375 19.09375 5.609375 36.375 \r\nQ 5.609375 53.65625 14.8125 63.9375 \r\nQ 24.03125 74.21875 39.40625 74.21875 \r\nz\r\n\" id=\"DejaVuSans-79\"/>\r\n      <path d=\"M 64.40625 67.28125 \r\nL 64.40625 56.890625 \r\nQ 59.421875 61.53125 53.78125 63.8125 \r\nQ 48.140625 66.109375 41.796875 66.109375 \r\nQ 29.296875 66.109375 22.65625 58.46875 \r\nQ 16.015625 50.828125 16.015625 36.375 \r\nQ 16.015625 21.96875 22.65625 14.328125 \r\nQ 29.296875 6.6875 41.796875 6.6875 \r\nQ 48.140625 6.6875 53.78125 8.984375 \r\nQ 59.421875 11.28125 64.40625 15.921875 \r\nL 64.40625 5.609375 \r\nQ 59.234375 2.09375 53.4375 0.328125 \r\nQ 47.65625 -1.421875 41.21875 -1.421875 \r\nQ 24.65625 -1.421875 15.125 8.703125 \r\nQ 5.609375 18.84375 5.609375 36.375 \r\nQ 5.609375 53.953125 15.125 64.078125 \r\nQ 24.65625 74.21875 41.21875 74.21875 \r\nQ 47.75 74.21875 53.53125 72.484375 \r\nQ 59.328125 70.75 64.40625 67.28125 \r\nz\r\n\" id=\"DejaVuSans-67\"/>\r\n      <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\n\" id=\"DejaVuSans-65\"/>\r\n     </defs>\r\n     <g transform=\"translate(194.159375 269.862812)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-201\"/>\r\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"123.486328\" xlink:href=\"#DejaVuSans-79\"/>\r\n      <use x=\"202.197266\" xlink:href=\"#DejaVuSans-67\"/>\r\n      <use x=\"272.021484\" xlink:href=\"#DejaVuSans-65\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m77f5a3e753\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m77f5a3e753\" y=\"230.620958\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.5 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 234.420177)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m77f5a3e753\" y=\"187.3547\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.6 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 191.153919)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m77f5a3e753\" y=\"144.088442\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.7 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 147.887661)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m77f5a3e753\" y=\"100.822184\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.8 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 104.621403)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m77f5a3e753\" y=\"57.555926\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.9 -->\r\n      <defs>\r\n       <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-57\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 61.355145)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_13\">\r\n     <!-- ACURÁCIA -->\r\n     <defs>\r\n      <path d=\"M 8.6875 72.90625 \r\nL 18.609375 72.90625 \r\nL 18.609375 28.609375 \r\nQ 18.609375 16.890625 22.84375 11.734375 \r\nQ 27.09375 6.59375 36.625 6.59375 \r\nQ 46.09375 6.59375 50.34375 11.734375 \r\nQ 54.59375 16.890625 54.59375 28.609375 \r\nL 54.59375 72.90625 \r\nL 64.5 72.90625 \r\nL 64.5 27.390625 \r\nQ 64.5 13.140625 57.4375 5.859375 \r\nQ 50.390625 -1.421875 36.625 -1.421875 \r\nQ 22.796875 -1.421875 15.734375 5.859375 \r\nQ 8.6875 13.140625 8.6875 27.390625 \r\nz\r\n\" id=\"DejaVuSans-85\"/>\r\n      <path d=\"M 44.390625 34.1875 \r\nQ 47.5625 33.109375 50.5625 29.59375 \r\nQ 53.5625 26.078125 56.59375 19.921875 \r\nL 66.609375 0 \r\nL 56 0 \r\nL 46.6875 18.703125 \r\nQ 43.0625 26.03125 39.671875 28.421875 \r\nQ 36.28125 30.8125 30.421875 30.8125 \r\nL 19.671875 30.8125 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nL 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.578125 72.90625 50.734375 67.671875 \r\nQ 56.890625 62.453125 56.890625 51.90625 \r\nQ 56.890625 45.015625 53.6875 40.46875 \r\nQ 50.484375 35.9375 44.390625 34.1875 \r\nz\r\nM 19.671875 64.796875 \r\nL 19.671875 38.921875 \r\nL 32.078125 38.921875 \r\nQ 39.203125 38.921875 42.84375 42.21875 \r\nQ 46.484375 45.515625 46.484375 51.90625 \r\nQ 46.484375 58.296875 42.84375 61.546875 \r\nQ 39.203125 64.796875 32.078125 64.796875 \r\nz\r\n\" id=\"DejaVuSans-82\"/>\r\n      <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\nM 36.859375 92.734375 \r\nL 45.90625 92.734375 \r\nL 34.765625 79.84375 \r\nL 27.296875 79.84375 \r\nz\r\n\" id=\"DejaVuSans-193\"/>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-73\"/>\r\n     </defs>\r\n     <g transform=\"translate(14.798438 158.343594)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"66.658203\" xlink:href=\"#DejaVuSans-67\"/>\r\n      <use x=\"136.482422\" xlink:href=\"#DejaVuSans-85\"/>\r\n      <use x=\"209.675781\" xlink:href=\"#DejaVuSans-82\"/>\r\n      <use x=\"275.158203\" xlink:href=\"#DejaVuSans-193\"/>\r\n      <use x=\"341.816406\" xlink:href=\"#DejaVuSans-67\"/>\r\n      <use x=\"411.640625\" xlink:href=\"#DejaVuSans-73\"/>\r\n      <use x=\"441.132812\" xlink:href=\"#DejaVuSans-65\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_12\">\r\n    <path clip-path=\"url(#p4bf08b45d8)\" d=\"M 58.999432 226.699941 \r\nL 71.173977 227.240782 \r\nL 83.348523 229.539303 \r\nL 95.523068 227.646412 \r\nL 107.697614 231.702614 \r\nL 119.872159 77.025734 \r\nL 132.046705 42.683155 \r\nL 144.22125 41.19587 \r\nL 156.395795 42.683155 \r\nL 168.570341 35.652382 \r\nL 180.744886 41.46629 \r\nL 192.919432 39.032559 \r\nL 205.093977 39.032559 \r\nL 217.268523 36.058013 \r\nL 229.443068 38.086114 \r\nL 241.617614 35.299284 \r\nL 253.792159 39.438189 \r\nL 265.966705 38.762138 \r\nL 278.14125 40.655055 \r\nL 290.315795 37.274878 \r\nL 302.490341 37.603555 \r\nL 314.664886 38.491744 \r\nL 326.839432 34.029886 \r\nL 339.013977 35.381962 \r\nL 351.188523 37.815693 \r\nL 363.363068 37.950903 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p4bf08b45d8)\" d=\"M 58.999432 194.926304 \r\nL 71.173977 187.084295 \r\nL 83.348523 199.79374 \r\nL 95.523068 194.926304 \r\nL 107.697614 190.329262 \r\nL 119.872159 52.958895 \r\nL 132.046705 63.775449 \r\nL 144.22125 44.305626 \r\nL 156.395795 47.550592 \r\nL 168.570341 42.953576 \r\nL 180.744886 43.494391 \r\nL 192.919432 46.468937 \r\nL 205.093977 38.626928 \r\nL 217.268523 42.142315 \r\nL 229.443068 47.280197 \r\nL 241.617614 44.576046 \r\nL 253.792159 45.928122 \r\nL 265.966705 42.142315 \r\nL 278.14125 48.091433 \r\nL 290.315795 36.734038 \r\nL 302.490341 35.381962 \r\nL 314.664886 38.356534 \r\nL 326.839432 37.004458 \r\nL 339.013977 46.468937 \r\nL 351.188523 38.356534 \r\nL 363.363068 42.142315 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 43.78125 241.58625 \r\nL 43.78125 24.14625 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 378.58125 241.58625 \r\nL 378.58125 24.14625 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 43.78125 241.58625 \r\nL 378.58125 241.58625 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 43.78125 24.14625 \r\nL 378.58125 24.14625 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_14\">\r\n    <!-- AVALIAÇÃO: ACURÁCIA -->\r\n    <defs>\r\n     <path d=\"M 28.609375 0 \r\nL 0.78125 72.90625 \r\nL 11.078125 72.90625 \r\nL 34.1875 11.53125 \r\nL 57.328125 72.90625 \r\nL 67.578125 72.90625 \r\nL 39.796875 0 \r\nz\r\n\" id=\"DejaVuSans-86\"/>\r\n     <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n     <path d=\"M 64.40625 67.28125 \r\nL 64.40625 56.890625 \r\nQ 59.421875 61.53125 53.78125 63.8125 \r\nQ 48.140625 66.109375 41.796875 66.109375 \r\nQ 29.296875 66.109375 22.65625 58.46875 \r\nQ 16.015625 50.828125 16.015625 36.375 \r\nQ 16.015625 21.96875 22.65625 14.328125 \r\nQ 29.296875 6.6875 41.796875 6.6875 \r\nQ 48.140625 6.6875 53.78125 8.984375 \r\nQ 59.421875 11.28125 64.40625 15.921875 \r\nL 64.40625 5.609375 \r\nQ 59.234375 2.09375 53.4375 0.328125 \r\nQ 47.65625 -1.421875 41.21875 -1.421875 \r\nQ 24.65625 -1.421875 15.125 8.703125 \r\nQ 5.609375 18.84375 5.609375 36.375 \r\nQ 5.609375 53.953125 15.125 64.078125 \r\nQ 24.65625 74.21875 41.21875 74.21875 \r\nQ 47.75 74.21875 53.53125 72.484375 \r\nQ 59.328125 70.75 64.40625 67.28125 \r\nz\r\nM 43.796875 0 \r\nQ 46.484375 -3.03125 47.796875 -5.59375 \r\nQ 49.125 -8.15625 49.125 -10.5 \r\nQ 49.125 -14.84375 46.1875 -17.0625 \r\nQ 43.265625 -19.28125 37.5 -19.28125 \r\nQ 35.25 -19.28125 33.125 -18.984375 \r\nQ 31 -18.703125 28.90625 -18.109375 \r\nL 28.90625 -11.71875 \r\nQ 30.5625 -12.546875 32.375 -12.90625 \r\nQ 34.1875 -13.28125 36.46875 -13.28125 \r\nQ 39.359375 -13.28125 40.8125 -12.109375 \r\nQ 42.28125 -10.9375 42.28125 -8.6875 \r\nQ 42.28125 -7.234375 41.234375 -5.109375 \r\nQ 40.1875 -2.984375 37.984375 0 \r\nz\r\n\" id=\"DejaVuSans-199\"/>\r\n     <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\nM 33.984375 83.5 \r\nL 31.203125 85.109375 \r\nQ 29.984375 85.796875 29.21875 86.0625 \r\nQ 28.46875 86.328125 27.875 86.328125 \r\nQ 26.125 86.328125 25.140625 85.109375 \r\nQ 24.171875 83.890625 24.171875 81.703125 \r\nL 24.171875 81.40625 \r\nL 18.0625 81.40625 \r\nQ 18.0625 86.328125 20.578125 89.203125 \r\nQ 23.09375 92.09375 27.296875 92.09375 \r\nQ 29.046875 92.09375 30.53125 91.703125 \r\nQ 32.03125 91.3125 34.375 90 \r\nL 37.15625 88.53125 \r\nQ 38.28125 87.890625 39.109375 87.59375 \r\nQ 39.9375 87.3125 40.671875 87.3125 \r\nQ 42.234375 87.3125 43.203125 88.546875 \r\nQ 44.1875 89.796875 44.1875 91.796875 \r\nL 44.1875 92.09375 \r\nL 50.296875 92.09375 \r\nQ 50.203125 87.21875 47.6875 84.3125 \r\nQ 45.171875 81.40625 41.0625 81.40625 \r\nQ 39.40625 81.40625 37.96875 81.796875 \r\nQ 36.53125 82.1875 33.984375 83.5 \r\nz\r\n\" id=\"DejaVuSans-195\"/>\r\n     <path d=\"M 11.71875 12.40625 \r\nL 22.015625 12.40625 \r\nL 22.015625 0 \r\nL 11.71875 0 \r\nz\r\nM 11.71875 51.703125 \r\nL 22.015625 51.703125 \r\nL 22.015625 39.3125 \r\nL 11.71875 39.3125 \r\nz\r\n\" id=\"DejaVuSans-58\"/>\r\n     <path id=\"DejaVuSans-32\"/>\r\n    </defs>\r\n    <g transform=\"translate(143.2125 18.14625)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"62.033203\" xlink:href=\"#DejaVuSans-86\"/>\r\n     <use x=\"124.066406\" xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"192.474609\" xlink:href=\"#DejaVuSans-76\"/>\r\n     <use x=\"248.1875\" xlink:href=\"#DejaVuSans-73\"/>\r\n     <use x=\"277.679688\" xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"344.337891\" xlink:href=\"#DejaVuSans-199\"/>\r\n     <use x=\"414.162109\" xlink:href=\"#DejaVuSans-195\"/>\r\n     <use x=\"480.820312\" xlink:href=\"#DejaVuSans-79\"/>\r\n     <use x=\"557.78125\" xlink:href=\"#DejaVuSans-58\"/>\r\n     <use x=\"591.472656\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"623.259766\" xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"689.917969\" xlink:href=\"#DejaVuSans-67\"/>\r\n     <use x=\"759.742188\" xlink:href=\"#DejaVuSans-85\"/>\r\n     <use x=\"832.935547\" xlink:href=\"#DejaVuSans-82\"/>\r\n     <use x=\"898.417969\" xlink:href=\"#DejaVuSans-193\"/>\r\n     <use x=\"965.076172\" xlink:href=\"#DejaVuSans-67\"/>\r\n     <use x=\"1034.900391\" xlink:href=\"#DejaVuSans-73\"/>\r\n     <use x=\"1064.392578\" xlink:href=\"#DejaVuSans-65\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 266.526563 236.58625 \r\nL 371.58125 236.58625 \r\nQ 373.58125 236.58625 373.58125 234.58625 \r\nL 373.58125 206.23 \r\nQ 373.58125 204.23 371.58125 204.23 \r\nL 266.526563 204.23 \r\nQ 264.526563 204.23 264.526563 206.23 \r\nL 264.526563 234.58625 \r\nQ 264.526563 236.58625 266.526563 236.58625 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_14\">\r\n     <path d=\"M 268.526563 212.328437 \r\nL 288.526563 212.328437 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_15\"/>\r\n    <g id=\"text_15\">\r\n     <!-- TREINAMENTO -->\r\n     <defs>\r\n      <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 23.09375 72.90625 \r\nL 55.421875 11.921875 \r\nL 55.421875 72.90625 \r\nL 64.984375 72.90625 \r\nL 64.984375 0 \r\nL 51.703125 0 \r\nL 19.390625 60.984375 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-78\"/>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 24.515625 72.90625 \r\nL 43.109375 23.296875 \r\nL 61.8125 72.90625 \r\nL 76.515625 72.90625 \r\nL 76.515625 0 \r\nL 66.890625 0 \r\nL 66.890625 64.015625 \r\nL 48.09375 14.015625 \r\nL 38.1875 14.015625 \r\nL 19.390625 64.015625 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-77\"/>\r\n     </defs>\r\n     <g transform=\"translate(296.526563 215.828437)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"61.083984\" xlink:href=\"#DejaVuSans-82\"/>\r\n      <use x=\"130.566406\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"193.75\" xlink:href=\"#DejaVuSans-73\"/>\r\n      <use x=\"223.242188\" xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"298.046875\" xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"366.455078\" xlink:href=\"#DejaVuSans-77\"/>\r\n      <use x=\"452.734375\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"515.917969\" xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"590.722656\" xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"651.806641\" xlink:href=\"#DejaVuSans-79\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_16\">\r\n     <path d=\"M 268.526563 227.006562 \r\nL 288.526563 227.006562 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_17\"/>\r\n    <g id=\"text_16\">\r\n     <!-- TESTE -->\r\n     <defs>\r\n      <path d=\"M 53.515625 70.515625 \r\nL 53.515625 60.890625 \r\nQ 47.90625 63.578125 42.921875 64.890625 \r\nQ 37.9375 66.21875 33.296875 66.21875 \r\nQ 25.25 66.21875 20.875 63.09375 \r\nQ 16.5 59.96875 16.5 54.203125 \r\nQ 16.5 49.359375 19.40625 46.890625 \r\nQ 22.3125 44.4375 30.421875 42.921875 \r\nL 36.375 41.703125 \r\nQ 47.40625 39.59375 52.65625 34.296875 \r\nQ 57.90625 29 57.90625 20.125 \r\nQ 57.90625 9.515625 50.796875 4.046875 \r\nQ 43.703125 -1.421875 29.984375 -1.421875 \r\nQ 24.8125 -1.421875 18.96875 -0.25 \r\nQ 13.140625 0.921875 6.890625 3.21875 \r\nL 6.890625 13.375 \r\nQ 12.890625 10.015625 18.65625 8.296875 \r\nQ 24.421875 6.59375 29.984375 6.59375 \r\nQ 38.421875 6.59375 43.015625 9.90625 \r\nQ 47.609375 13.234375 47.609375 19.390625 \r\nQ 47.609375 24.75 44.3125 27.78125 \r\nQ 41.015625 30.8125 33.5 32.328125 \r\nL 27.484375 33.5 \r\nQ 16.453125 35.6875 11.515625 40.375 \r\nQ 6.59375 45.0625 6.59375 53.421875 \r\nQ 6.59375 63.09375 13.40625 68.65625 \r\nQ 20.21875 74.21875 32.171875 74.21875 \r\nQ 37.3125 74.21875 42.625 73.28125 \r\nQ 47.953125 72.359375 53.515625 70.515625 \r\nz\r\n\" id=\"DejaVuSans-83\"/>\r\n     </defs>\r\n     <g transform=\"translate(296.526563 230.506562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"61.083984\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"124.267578\" xlink:href=\"#DejaVuSans-83\"/>\r\n      <use x=\"187.744141\" xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"248.828125\" xlink:href=\"#DejaVuSans-69\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p4bf08b45d8\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"24.14625\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"279.065625pt\" version=\"1.1\" viewBox=\"0 0 385.78125 279.065625\" width=\"385.78125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 279.065625 \r\nL 385.78125 279.065625 \r\nL 385.78125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 43.78125 241.509375 \r\nL 378.58125 241.509375 \r\nL 378.58125 24.069375 \r\nL 43.78125 24.069375 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m89890f7aa5\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.999432\" xlink:href=\"#m89890f7aa5\" y=\"241.509375\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(55.818182 256.107812)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"119.872159\" xlink:href=\"#m89890f7aa5\" y=\"241.509375\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(116.690909 256.107812)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"180.744886\" xlink:href=\"#m89890f7aa5\" y=\"241.509375\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(174.382386 256.107812)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.617614\" xlink:href=\"#m89890f7aa5\" y=\"241.509375\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(235.255114 256.107812)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.490341\" xlink:href=\"#m89890f7aa5\" y=\"241.509375\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(296.127841 256.107812)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"363.363068\" xlink:href=\"#m89890f7aa5\" y=\"241.509375\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(357.000568 256.107812)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_7\">\r\n     <!-- ÉPOCA -->\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\nM 35.40625 92.734375 \r\nL 44.4375 92.734375 \r\nL 33.296875 79.84375 \r\nL 25.828125 79.84375 \r\nz\r\n\" id=\"DejaVuSans-201\"/>\r\n      <path d=\"M 19.671875 64.796875 \r\nL 19.671875 37.40625 \r\nL 32.078125 37.40625 \r\nQ 38.96875 37.40625 42.71875 40.96875 \r\nQ 46.484375 44.53125 46.484375 51.125 \r\nQ 46.484375 57.671875 42.71875 61.234375 \r\nQ 38.96875 64.796875 32.078125 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.34375 72.90625 50.609375 67.359375 \r\nQ 56.890625 61.8125 56.890625 51.125 \r\nQ 56.890625 40.328125 50.609375 34.8125 \r\nQ 44.34375 29.296875 32.078125 29.296875 \r\nL 19.671875 29.296875 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-80\"/>\r\n      <path d=\"M 39.40625 66.21875 \r\nQ 28.65625 66.21875 22.328125 58.203125 \r\nQ 16.015625 50.203125 16.015625 36.375 \r\nQ 16.015625 22.609375 22.328125 14.59375 \r\nQ 28.65625 6.59375 39.40625 6.59375 \r\nQ 50.140625 6.59375 56.421875 14.59375 \r\nQ 62.703125 22.609375 62.703125 36.375 \r\nQ 62.703125 50.203125 56.421875 58.203125 \r\nQ 50.140625 66.21875 39.40625 66.21875 \r\nz\r\nM 39.40625 74.21875 \r\nQ 54.734375 74.21875 63.90625 63.9375 \r\nQ 73.09375 53.65625 73.09375 36.375 \r\nQ 73.09375 19.140625 63.90625 8.859375 \r\nQ 54.734375 -1.421875 39.40625 -1.421875 \r\nQ 24.03125 -1.421875 14.8125 8.828125 \r\nQ 5.609375 19.09375 5.609375 36.375 \r\nQ 5.609375 53.65625 14.8125 63.9375 \r\nQ 24.03125 74.21875 39.40625 74.21875 \r\nz\r\n\" id=\"DejaVuSans-79\"/>\r\n      <path d=\"M 64.40625 67.28125 \r\nL 64.40625 56.890625 \r\nQ 59.421875 61.53125 53.78125 63.8125 \r\nQ 48.140625 66.109375 41.796875 66.109375 \r\nQ 29.296875 66.109375 22.65625 58.46875 \r\nQ 16.015625 50.828125 16.015625 36.375 \r\nQ 16.015625 21.96875 22.65625 14.328125 \r\nQ 29.296875 6.6875 41.796875 6.6875 \r\nQ 48.140625 6.6875 53.78125 8.984375 \r\nQ 59.421875 11.28125 64.40625 15.921875 \r\nL 64.40625 5.609375 \r\nQ 59.234375 2.09375 53.4375 0.328125 \r\nQ 47.65625 -1.421875 41.21875 -1.421875 \r\nQ 24.65625 -1.421875 15.125 8.703125 \r\nQ 5.609375 18.84375 5.609375 36.375 \r\nQ 5.609375 53.953125 15.125 64.078125 \r\nQ 24.65625 74.21875 41.21875 74.21875 \r\nQ 47.75 74.21875 53.53125 72.484375 \r\nQ 59.328125 70.75 64.40625 67.28125 \r\nz\r\n\" id=\"DejaVuSans-67\"/>\r\n      <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\n\" id=\"DejaVuSans-65\"/>\r\n     </defs>\r\n     <g transform=\"translate(194.159375 269.785937)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-201\"/>\r\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"123.486328\" xlink:href=\"#DejaVuSans-79\"/>\r\n      <use x=\"202.197266\" xlink:href=\"#DejaVuSans-67\"/>\r\n      <use x=\"272.021484\" xlink:href=\"#DejaVuSans-65\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m5f6954798a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m5f6954798a\" y=\"214.13857\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.6 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 217.937789)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m5f6954798a\" y=\"184.837528\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.8 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 188.636746)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m5f6954798a\" y=\"155.536485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(20.878125 159.335704)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m5f6954798a\" y=\"126.235443\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 1.2 -->\r\n      <g transform=\"translate(20.878125 130.034662)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m5f6954798a\" y=\"96.934401\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 1.4 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 100.733619)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m5f6954798a\" y=\"67.633358\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 1.6 -->\r\n      <g transform=\"translate(20.878125 71.432577)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m5f6954798a\" y=\"38.332316\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 1.8 -->\r\n      <g transform=\"translate(20.878125 42.131535)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_15\">\r\n     <!-- LOSS -->\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n      <path d=\"M 53.515625 70.515625 \r\nL 53.515625 60.890625 \r\nQ 47.90625 63.578125 42.921875 64.890625 \r\nQ 37.9375 66.21875 33.296875 66.21875 \r\nQ 25.25 66.21875 20.875 63.09375 \r\nQ 16.5 59.96875 16.5 54.203125 \r\nQ 16.5 49.359375 19.40625 46.890625 \r\nQ 22.3125 44.4375 30.421875 42.921875 \r\nL 36.375 41.703125 \r\nQ 47.40625 39.59375 52.65625 34.296875 \r\nQ 57.90625 29 57.90625 20.125 \r\nQ 57.90625 9.515625 50.796875 4.046875 \r\nQ 43.703125 -1.421875 29.984375 -1.421875 \r\nQ 24.8125 -1.421875 18.96875 -0.25 \r\nQ 13.140625 0.921875 6.890625 3.21875 \r\nL 6.890625 13.375 \r\nQ 12.890625 10.015625 18.65625 8.296875 \r\nQ 24.421875 6.59375 29.984375 6.59375 \r\nQ 38.421875 6.59375 43.015625 9.90625 \r\nQ 47.609375 13.234375 47.609375 19.390625 \r\nQ 47.609375 24.75 44.3125 27.78125 \r\nQ 41.015625 30.8125 33.5 32.328125 \r\nL 27.484375 33.5 \r\nQ 16.453125 35.6875 11.515625 40.375 \r\nQ 6.59375 45.0625 6.59375 53.421875 \r\nQ 6.59375 63.09375 13.40625 68.65625 \r\nQ 20.21875 74.21875 32.171875 74.21875 \r\nQ 37.3125 74.21875 42.625 73.28125 \r\nQ 47.953125 72.359375 53.515625 70.515625 \r\nz\r\n\" id=\"DejaVuSans-83\"/>\r\n     </defs>\r\n     <g transform=\"translate(14.798438 145.678437)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"52.087891\" xlink:href=\"#DejaVuSans-79\"/>\r\n      <use x=\"130.798828\" xlink:href=\"#DejaVuSans-83\"/>\r\n      <use x=\"194.275391\" xlink:href=\"#DejaVuSans-83\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#p57a7d1b8ec)\" d=\"M 58.999432 33.953011 \r\nL 71.173977 41.710082 \r\nL 83.348523 45.430377 \r\nL 95.523068 57.543531 \r\nL 107.697614 58.577341 \r\nL 119.872159 194.748903 \r\nL 132.046705 215.649934 \r\nL 144.22125 220.315371 \r\nL 156.395795 220.436 \r\nL 168.570341 226.300884 \r\nL 180.744886 221.250383 \r\nL 192.919432 222.599398 \r\nL 205.093977 224.740074 \r\nL 217.268523 226.394731 \r\nL 229.443068 224.837667 \r\nL 241.617614 227.061318 \r\nL 253.792159 226.911304 \r\nL 265.966705 225.184788 \r\nL 278.14125 223.798565 \r\nL 290.315795 228.208667 \r\nL 302.490341 229.088346 \r\nL 314.664886 227.164247 \r\nL 326.839432 228.446808 \r\nL 339.013977 228.762824 \r\nL 351.188523 227.591575 \r\nL 363.363068 226.524704 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#p57a7d1b8ec)\" d=\"M 58.999432 106.598943 \r\nL 71.173977 113.79363 \r\nL 83.348523 115.673015 \r\nL 95.523068 119.93278 \r\nL 107.697614 125.435566 \r\nL 119.872159 210.73165 \r\nL 132.046705 206.149931 \r\nL 144.22125 225.204392 \r\nL 156.395795 223.395259 \r\nL 168.570341 226.281018 \r\nL 180.744886 225.101071 \r\nL 192.919432 223.540164 \r\nL 205.093977 228.162918 \r\nL 217.268523 225.49429 \r\nL 229.443068 224.503993 \r\nL 241.617614 225.243295 \r\nL 253.792159 224.928126 \r\nL 265.966705 227.879525 \r\nL 278.14125 223.479623 \r\nL 290.315795 229.107627 \r\nL 302.490341 231.625739 \r\nL 314.664886 229.24907 \r\nL 326.839432 230.391821 \r\nL 339.013977 223.638465 \r\nL 351.188523 229.500694 \r\nL 363.363068 227.915049 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 43.78125 241.509375 \r\nL 43.78125 24.069375 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 378.58125 241.509375 \r\nL 378.58125 24.069375 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 43.78125 241.509375 \r\nL 378.58125 241.509375 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 43.78125 24.069375 \r\nL 378.58125 24.069375 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_16\">\r\n    <!-- AVALIAÇÃO: LOSS -->\r\n    <defs>\r\n     <path d=\"M 28.609375 0 \r\nL 0.78125 72.90625 \r\nL 11.078125 72.90625 \r\nL 34.1875 11.53125 \r\nL 57.328125 72.90625 \r\nL 67.578125 72.90625 \r\nL 39.796875 0 \r\nz\r\n\" id=\"DejaVuSans-86\"/>\r\n     <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-73\"/>\r\n     <path d=\"M 64.40625 67.28125 \r\nL 64.40625 56.890625 \r\nQ 59.421875 61.53125 53.78125 63.8125 \r\nQ 48.140625 66.109375 41.796875 66.109375 \r\nQ 29.296875 66.109375 22.65625 58.46875 \r\nQ 16.015625 50.828125 16.015625 36.375 \r\nQ 16.015625 21.96875 22.65625 14.328125 \r\nQ 29.296875 6.6875 41.796875 6.6875 \r\nQ 48.140625 6.6875 53.78125 8.984375 \r\nQ 59.421875 11.28125 64.40625 15.921875 \r\nL 64.40625 5.609375 \r\nQ 59.234375 2.09375 53.4375 0.328125 \r\nQ 47.65625 -1.421875 41.21875 -1.421875 \r\nQ 24.65625 -1.421875 15.125 8.703125 \r\nQ 5.609375 18.84375 5.609375 36.375 \r\nQ 5.609375 53.953125 15.125 64.078125 \r\nQ 24.65625 74.21875 41.21875 74.21875 \r\nQ 47.75 74.21875 53.53125 72.484375 \r\nQ 59.328125 70.75 64.40625 67.28125 \r\nz\r\nM 43.796875 0 \r\nQ 46.484375 -3.03125 47.796875 -5.59375 \r\nQ 49.125 -8.15625 49.125 -10.5 \r\nQ 49.125 -14.84375 46.1875 -17.0625 \r\nQ 43.265625 -19.28125 37.5 -19.28125 \r\nQ 35.25 -19.28125 33.125 -18.984375 \r\nQ 31 -18.703125 28.90625 -18.109375 \r\nL 28.90625 -11.71875 \r\nQ 30.5625 -12.546875 32.375 -12.90625 \r\nQ 34.1875 -13.28125 36.46875 -13.28125 \r\nQ 39.359375 -13.28125 40.8125 -12.109375 \r\nQ 42.28125 -10.9375 42.28125 -8.6875 \r\nQ 42.28125 -7.234375 41.234375 -5.109375 \r\nQ 40.1875 -2.984375 37.984375 0 \r\nz\r\n\" id=\"DejaVuSans-199\"/>\r\n     <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\nM 33.984375 83.5 \r\nL 31.203125 85.109375 \r\nQ 29.984375 85.796875 29.21875 86.0625 \r\nQ 28.46875 86.328125 27.875 86.328125 \r\nQ 26.125 86.328125 25.140625 85.109375 \r\nQ 24.171875 83.890625 24.171875 81.703125 \r\nL 24.171875 81.40625 \r\nL 18.0625 81.40625 \r\nQ 18.0625 86.328125 20.578125 89.203125 \r\nQ 23.09375 92.09375 27.296875 92.09375 \r\nQ 29.046875 92.09375 30.53125 91.703125 \r\nQ 32.03125 91.3125 34.375 90 \r\nL 37.15625 88.53125 \r\nQ 38.28125 87.890625 39.109375 87.59375 \r\nQ 39.9375 87.3125 40.671875 87.3125 \r\nQ 42.234375 87.3125 43.203125 88.546875 \r\nQ 44.1875 89.796875 44.1875 91.796875 \r\nL 44.1875 92.09375 \r\nL 50.296875 92.09375 \r\nQ 50.203125 87.21875 47.6875 84.3125 \r\nQ 45.171875 81.40625 41.0625 81.40625 \r\nQ 39.40625 81.40625 37.96875 81.796875 \r\nQ 36.53125 82.1875 33.984375 83.5 \r\nz\r\n\" id=\"DejaVuSans-195\"/>\r\n     <path d=\"M 11.71875 12.40625 \r\nL 22.015625 12.40625 \r\nL 22.015625 0 \r\nL 11.71875 0 \r\nz\r\nM 11.71875 51.703125 \r\nL 22.015625 51.703125 \r\nL 22.015625 39.3125 \r\nL 11.71875 39.3125 \r\nz\r\n\" id=\"DejaVuSans-58\"/>\r\n     <path id=\"DejaVuSans-32\"/>\r\n    </defs>\r\n    <g transform=\"translate(158.318438 18.069375)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"62.033203\" xlink:href=\"#DejaVuSans-86\"/>\r\n     <use x=\"124.066406\" xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"192.474609\" xlink:href=\"#DejaVuSans-76\"/>\r\n     <use x=\"248.1875\" xlink:href=\"#DejaVuSans-73\"/>\r\n     <use x=\"277.679688\" xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"344.337891\" xlink:href=\"#DejaVuSans-199\"/>\r\n     <use x=\"414.162109\" xlink:href=\"#DejaVuSans-195\"/>\r\n     <use x=\"480.820312\" xlink:href=\"#DejaVuSans-79\"/>\r\n     <use x=\"557.78125\" xlink:href=\"#DejaVuSans-58\"/>\r\n     <use x=\"591.472656\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"623.259766\" xlink:href=\"#DejaVuSans-76\"/>\r\n     <use x=\"675.347656\" xlink:href=\"#DejaVuSans-79\"/>\r\n     <use x=\"754.058594\" xlink:href=\"#DejaVuSans-83\"/>\r\n     <use x=\"817.535156\" xlink:href=\"#DejaVuSans-83\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 266.526563 61.425625 \r\nL 371.58125 61.425625 \r\nQ 373.58125 61.425625 373.58125 59.425625 \r\nL 373.58125 31.069375 \r\nQ 373.58125 29.069375 371.58125 29.069375 \r\nL 266.526563 29.069375 \r\nQ 264.526563 29.069375 264.526563 31.069375 \r\nL 264.526563 59.425625 \r\nQ 264.526563 61.425625 266.526563 61.425625 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_16\">\r\n     <path d=\"M 268.526563 37.167812 \r\nL 288.526563 37.167812 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_17\"/>\r\n    <g id=\"text_17\">\r\n     <!-- TREINAMENTO -->\r\n     <defs>\r\n      <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n      <path d=\"M 44.390625 34.1875 \r\nQ 47.5625 33.109375 50.5625 29.59375 \r\nQ 53.5625 26.078125 56.59375 19.921875 \r\nL 66.609375 0 \r\nL 56 0 \r\nL 46.6875 18.703125 \r\nQ 43.0625 26.03125 39.671875 28.421875 \r\nQ 36.28125 30.8125 30.421875 30.8125 \r\nL 19.671875 30.8125 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nL 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.578125 72.90625 50.734375 67.671875 \r\nQ 56.890625 62.453125 56.890625 51.90625 \r\nQ 56.890625 45.015625 53.6875 40.46875 \r\nQ 50.484375 35.9375 44.390625 34.1875 \r\nz\r\nM 19.671875 64.796875 \r\nL 19.671875 38.921875 \r\nL 32.078125 38.921875 \r\nQ 39.203125 38.921875 42.84375 42.21875 \r\nQ 46.484375 45.515625 46.484375 51.90625 \r\nQ 46.484375 58.296875 42.84375 61.546875 \r\nQ 39.203125 64.796875 32.078125 64.796875 \r\nz\r\n\" id=\"DejaVuSans-82\"/>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 23.09375 72.90625 \r\nL 55.421875 11.921875 \r\nL 55.421875 72.90625 \r\nL 64.984375 72.90625 \r\nL 64.984375 0 \r\nL 51.703125 0 \r\nL 19.390625 60.984375 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-78\"/>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 24.515625 72.90625 \r\nL 43.109375 23.296875 \r\nL 61.8125 72.90625 \r\nL 76.515625 72.90625 \r\nL 76.515625 0 \r\nL 66.890625 0 \r\nL 66.890625 64.015625 \r\nL 48.09375 14.015625 \r\nL 38.1875 14.015625 \r\nL 19.390625 64.015625 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-77\"/>\r\n     </defs>\r\n     <g transform=\"translate(296.526563 40.667812)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"61.083984\" xlink:href=\"#DejaVuSans-82\"/>\r\n      <use x=\"130.566406\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"193.75\" xlink:href=\"#DejaVuSans-73\"/>\r\n      <use x=\"223.242188\" xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"298.046875\" xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"366.455078\" xlink:href=\"#DejaVuSans-77\"/>\r\n      <use x=\"452.734375\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"515.917969\" xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"590.722656\" xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"651.806641\" xlink:href=\"#DejaVuSans-79\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_18\">\r\n     <path d=\"M 268.526563 51.845937 \r\nL 288.526563 51.845937 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_19\"/>\r\n    <g id=\"text_18\">\r\n     <!-- TESTE -->\r\n     <g transform=\"translate(296.526563 55.345937)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"61.083984\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"124.267578\" xlink:href=\"#DejaVuSans-83\"/>\r\n      <use x=\"187.744141\" xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"248.828125\" xlink:href=\"#DejaVuSans-69\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p57a7d1b8ec\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"24.069375\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# GRÁFICO CONTENDO A INFORMAÇÃO DA ACURÁCIA\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('AVALIAÇÃO: ACURÁCIA')\n",
    "plt.ylabel('ACURÁCIA')\n",
    "plt.xlabel('ÉPOCA')\n",
    "plt.legend(['TREINAMENTO', 'TESTE'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "logging.info('GRÁFICO DE ACURÁCIA GERADO COM SUCESSO')\n",
    "\n",
    "# GRÁFICO CONTENDO A INFORMAÇÃO DE LOSS\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('AVALIAÇÃO: LOSS')\n",
    "plt.ylabel('LOSS')\n",
    "plt.xlabel('ÉPOCA')\n",
    "plt.legend(['TREINAMENTO', 'TESTE'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "logging.info('GRÁFICO DE LOSS GERADO COM SUCESSO')\n",
    "logging.info('PROCESSO FINALIZADO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}